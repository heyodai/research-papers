{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import Workbook\n",
    "\n",
    "GOOGLE_DRIVE_PATH = '/Users/odai/Library/CloudStorage/GoogleDrive-heyodai@gmail.com/My Drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>notes</th>\n",
       "      <th>arxiv_url</th>\n",
       "      <th>em_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [arxiv_id, title, publication_date, abstract, notes, arxiv_url, em_url]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Initial dataframe setup\n",
    "# df = pd.DataFrame(\n",
    "#     columns=[\n",
    "#         \"arxiv_id\",\n",
    "#         \"title\",\n",
    "#         \"publication_date\",\n",
    "#         \"abstract\",\n",
    "#         \"notes\",\n",
    "#         \"arxiv_url\",\n",
    "#         \"em_url\",\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# df.to_excel(f\"{GOOGLE_DRIVE_PATH}/arxiv_papers.xlsx\", index=False)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(url='https://www.emergentmind.com/papers/2403.14562', notes='This is a test note')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get CLI argument of URL\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"url\", help=\"URL of the Emergent Mind paper\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# # Demo for Jupyter development\n",
    "# args = argparse.Namespace()\n",
    "# args.url = 'https://www.emergentmind.com/papers/2403.14562'\n",
    "# args.notes = 'This is a test note'\n",
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>notes</th>\n",
       "      <th>arxiv_url</th>\n",
       "      <th>em_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [arxiv_id, title, publication_date, abstract, notes, arxiv_url, em_url]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the excel file\n",
    "df = pd.read_excel(f\"{GOOGLE_DRIVE_PATH}/arxiv_papers.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html class=\"bg-stone-100\">\n",
       "<head>\n",
       "<title>2403.14562 - The Era of Semantic Decoding</title>\n",
       "<meta content=\"2403.14562 - The Era of Semantic Decoding\" property=\"og:title\"/>\n",
       "<meta content=\"2403.14562 - The Era of Semantic Decoding\" property=\"twitter:title\"/>\n",
       "<meta content=\"This paper explores semantic decoding in AI, highlighting its shift from syntactic processing to optimizing semantic exchanges between models, humans, and tools.\" name=\"description\"/>\n",
       "<meta content=\"This paper explores semantic decoding in AI, highlighting its shift from syntactic processing to optimizing semantic exchanges between models, humans, and tools.\" property=\"og:description\"/>\n",
       "<meta content=\"This paper explores semantic decoding in AI, highlighting its shift from syntactic processing to optimizing semantic exchanges between models, humans, and tools.\" property=\"twitter:description\"/>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<meta content=\"https://www.emergentmind.com/papers/2403.14562\" property=\"og:url\"/>\n",
       "<meta content=\"website\" property=\"og:type\"/>\n",
       "<link href=\"https://www.emergentmind.com/papers/2403.14562\" rel=\"canonical\"/>\n",
       "<meta content=\"https://www.emergentmind.com/assets/og_image_thumbnail-a9dad7b02cfe6ca45a3794c8f5ca30dc84a45c2c32c1a9fa0a1ec778738b7780.jpg\" property=\"og:image\"/>\n",
       "<meta content=\"https://www.emergentmind.com/assets/summary_large_image_thumbnail-efa4d0360543e59922e124e877d443c92ce4676c27d9b237478ae703f1a2da4f.jpg\" property=\"twitter:image\"/>\n",
       "<meta content=\"summary_large_image\" property=\"twitter:card\"/>\n",
       "<meta content=\"@emergentmind\" property=\"twitter:site\"/>\n",
       "<link href=\"https://www.emergentmind.com/assets/logo/favicon-e0f26fd04308a9c98635aa08353f11780220c26740b7c8733ca2c4a5bd79040b.png\" rel=\"icon\" sizes=\"any\"/>\n",
       "<link href=\"https://www.emergentmind.com/assets/logo/icon-ca36f21ff6275fcde05a9be02ad97f58b413b83ff4b2e727f91cce8442f65515.svg\" rel=\"icon\" type=\"image/svg+xml\"/>\n",
       "<link href=\"https://www.emergentmind.com/assets/logo/apple-touch-icon-ad1f78e0419265ed63adfe2b5f0dd8f3835497e464535be5da744591c0c096db.png\" rel=\"apple-touch-icon\"/>\n",
       "<link as=\"font\" crossorigin=\"anonymous\" href=\"/assets/sitka_text_regular-9bb187ed85097383d9b0b3b1609fbd27f1020fc962b84e79736e09df931b8de4.woff2\" rel=\"preload\" type=\"font/woff2\"/>\n",
       "<meta content=\"authenticity_token\" name=\"csrf-param\"/>\n",
       "<meta content=\"40908gQR8yuNbBBT7-4KeFq3LzIn5u2l6Ch6Mk8iKQ64ANeh2iZf-6vEjdHZ3f2JibPvsXtejnoJ1KHvwomiUQ\" name=\"csrf-token\"/>\n",
       "<script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=G-MCBE4ZD8TH\"></script>\n",
       "<script>\n",
       "    window.dataLayer = window.dataLayer || [];\n",
       "    function gtag(){dataLayer.push(arguments);}\n",
       "    gtag('js', new Date());\n",
       "\n",
       "    gtag('config', 'G-MCBE4ZD8TH');\n",
       "  </script>\n",
       "<script async=\"\" charset=\"utf-8\" src=\"https://platform.twitter.com/widgets.js\"></script>\n",
       "<script>\n",
       "    (function(h,o,t,j,a,r){\n",
       "        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};\n",
       "        h._hjSettings={hjid:3768487,hjsv:6};\n",
       "        a=o.getElementsByTagName('head')[0];\n",
       "        r=o.createElement('script');r.async=1;\n",
       "        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;\n",
       "        a.appendChild(r);\n",
       "    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');\n",
       "</script>\n",
       "<script async=\"\" src=\"https://cdn.headwayapp.co/widget.js\"></script>\n",
       "<link href=\"https://unpkg.com/tippy.js@6/dist/tippy.css\" rel=\"stylesheet\">\n",
       "<link href=\"/assets/font-face-c978e26d57ba235ae7167711c4b6cbf0e83988b7148a2c449216864d2f3c857c.css\" rel=\"stylesheet\"/>\n",
       "<link href=\"/assets/tailwind-bc79238a81156e9e879d5406c83ab9e865918f306afd9db5b6aa4075cab0c60f.css\" rel=\"stylesheet\"/>\n",
       "<script data-turbo-track=\"reload\" type=\"importmap\">{\n",
       "  \"imports\": {\n",
       "    \"application\": \"/assets/application-196b7076375897afe92ce1cc15be0ea6f6e342740999ed40a8a0935067cc0643.js\",\n",
       "    \"@hotwired/turbo-rails\": \"/assets/turbo.min-569fe252dd55eef2e3cff9a6e83c8b9a2b0e2374a72d15522515e1ff9999ec78.js\",\n",
       "    \"@hotwired/stimulus\": \"/assets/stimulus.min-59f6a188a51873d87a6ae8218ac6e829404b5cacd7f2a8fb7249abfdec5ece6a.js\",\n",
       "    \"@hotwired/stimulus-loading\": \"/assets/stimulus-loading-6024ee603e0509bba59098881b54a52936debca30ff797835b5ec6a4ef77ba37.js\",\n",
       "    \"alpinejs\": \"https://ga.jspm.io/npm:alpinejs@3.10.2/dist/module.esm.js\",\n",
       "    \"reqwest\": \"https://ga.jspm.io/npm:reqwest@2.0.5/reqwest.js\",\n",
       "    \"xhr2\": \"https://ga.jspm.io/npm:xhr2@0.2.1/lib/browser.js\",\n",
       "    \"linkify-string\": \"https://ga.jspm.io/npm:linkify-string@4.0.2/dist/linkify-string.es.js\",\n",
       "    \"linkifyjs\": \"https://ga.jspm.io/npm:linkifyjs@4.0.2/dist/linkify.es.js\",\n",
       "    \"@ryangjchandler/alpine-tooltip\": \"https://ga.jspm.io/npm:@ryangjchandler/alpine-tooltip@1.2.0/dist/module.esm.js\",\n",
       "    \"luxon\": \"/assets/luxon-ae68e346c68113dab2a7d3bdd0836fad456aff6c699b778a37c2c4940d47ccfd.js\",\n",
       "    \"lodash\": \"https://ga.jspm.io/npm:lodash@4.17.21/lodash.js\",\n",
       "    \"js-cookie\": \"https://ga.jspm.io/npm:js-cookie@3.0.5/dist/js.cookie.mjs\",\n",
       "    \"@alpinejs/collapse\": \"https://ga.jspm.io/npm:@alpinejs/collapse@3.13.3/dist/module.esm.js\",\n",
       "    \"mixpanel-browser\": \"https://ga.jspm.io/npm:mixpanel-browser@2.48.1/dist/mixpanel.cjs.js\"\n",
       "  }\n",
       "}</script>\n",
       "<link href=\"/assets/application-196b7076375897afe92ce1cc15be0ea6f6e342740999ed40a8a0935067cc0643.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"/assets/turbo.min-569fe252dd55eef2e3cff9a6e83c8b9a2b0e2374a72d15522515e1ff9999ec78.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"/assets/stimulus.min-59f6a188a51873d87a6ae8218ac6e829404b5cacd7f2a8fb7249abfdec5ece6a.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"/assets/stimulus-loading-6024ee603e0509bba59098881b54a52936debca30ff797835b5ec6a4ef77ba37.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:alpinejs@3.10.2/dist/module.esm.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:reqwest@2.0.5/reqwest.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:xhr2@0.2.1/lib/browser.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:linkify-string@4.0.2/dist/linkify-string.es.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:linkifyjs@4.0.2/dist/linkify.es.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:@ryangjchandler/alpine-tooltip@1.2.0/dist/module.esm.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"/assets/luxon-ae68e346c68113dab2a7d3bdd0836fad456aff6c699b778a37c2c4940d47ccfd.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:lodash@4.17.21/lodash.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:js-cookie@3.0.5/dist/js.cookie.mjs\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:@alpinejs/collapse@3.13.3/dist/module.esm.js\" rel=\"modulepreload\"/>\n",
       "<link href=\"https://ga.jspm.io/npm:mixpanel-browser@2.48.1/dist/mixpanel.cjs.js\" rel=\"modulepreload\"/>\n",
       "<script type=\"module\">import \"application\"</script>\n",
       "</link></head>\n",
       "<body>\n",
       "<div class=\"h-[44px]\">\n",
       "<div class=\"container px-2 sm:px-4 mx-auto flex justify-between h-full\">\n",
       "<!-- begin: Main Navigation -->\n",
       "<nav class=\"flex w-full\">\n",
       "<a class=\"group h-full inline-block flex items-center font-ff-meta\" data-turbo=\"false\" href=\"https://www.emergentmind.com/\">\n",
       "<svg class=\"inline-block mr-2 -translate-y-0.1\" fill=\"none\" height=\"35\" viewbox=\"0 0 35 35\" width=\"35\" xmlns=\"http://www.w3.org/2000/svg\"><g clip-path=\"url(#a)\"><circle cx=\"17.5\" cy=\"17.5\" fill=\"#FADD07\" r=\"17.5\"></circle><path d=\"M32.976 35H17.683c-1.02 0-1.385-1.347-.506-1.863l10.56-6.19a1 1 0 0 1 1.3.256l4.734 6.19A1 1 0 0 1 32.976 35Z\" fill=\"#FADD07\"></path><path d=\"m10.616 9.567.516.516M17.714 7v.73M27.38 16.665h-.73M8.78 16.665h-.731M24.813 9.567l-.516.516M21.774 14.601c.42.725.64 1.549.633 2.386-.003.87-.25 1.72-.71 2.457-.154.246-.298.462-.43.66-.478.716-.805 1.206-.897 2.082h-5.31c-.09-.905-.423-1.396-.94-2.163-.105-.155-.217-.321-.337-.504a4.694 4.694 0 1 1 7.991-4.918ZM19.336 25.429h-3.243\" stroke=\"#231E21\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.75\"></path></g><defs><clippath id=\"a\"><path d=\"M0 0h35v35H0z\" fill=\"#fff\"></path></clippath></defs></svg>\n",
       "<span class=\"hidden text-neutral-500/90 group-hover:text-active-link-color transition duration-100 ease-out sm:block text-lg font-semibold whitespace-nowrap -translate-y-0.1\">Emergent Mind</span>\n",
       "</a>\n",
       "<div class=\"flex w-full items-center justify-between lg:justify-start space-x-2.1\">\n",
       "<div class=\"relative\">\n",
       "<form :class=\"focused &amp;&amp; 'border-gray-400'\" action=\"/search\" class=\"bg-[#E9EAE6] ml-2 sm:ml-4 w-[255px] xs:w-[300px] md:w-[320px] flex list-none border-b border-r border-l border-gray-200 rounded-b-lg items-center relative focus-within:shadow-innerX hover:shadow-innerX h-[44px]\" method=\"get\" x-data=\"{ focused: false }\" x-init=\"() =&gt; { if($refs.search.value !== '') focused = true }\" x-on:click.away=\"if($refs.search.value === '') focused = false\" x-on:keydown.escape=\"focused = false\">\n",
       "<input class=\"search-input !placeholder-red-400\" id=\"search\" name=\"q\" placeholder=\"arXiv id, url, topic, or author\" type=\"text\" value=\"\" x-on:focus=\"focused = true\" x-ref=\"search\"/>\n",
       "<!-- begin: Magnifying Glass -->\n",
       "<button class=\"!cursor-pointer absolute pl-2.5 right-3 cursor-text inline-block\">\n",
       "<svg class=\"text-gray-400 hover:text-gray-500\" fill=\"none\" height=\"17\" viewbox=\"0 0 18 17\" width=\"18\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<g opacity=\"0.8\">\n",
       "<path d=\"M16.7439 16L13.9878 13.2902\" stroke=\"#68685E\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"></path>\n",
       "<path d=\"M8.65813 15.0993C13.2464 15.0993 15.8276 12.5614 15.8276 8.05031C15.8276 3.5392 13.2464 1 8.65813 1C4.06991 1 1.4873 3.5379 1.4873 8.05031C1.4873 12.5627 4.06859 15.0993 8.65813 15.0993Z\" stroke=\"#68685E\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"></path>\n",
       "</g>\n",
       "</svg>\n",
       "</button>\n",
       "<!-- /end: Magnifying Glass -->\n",
       "</form>\n",
       "</div>\n",
       "<div @click.outside=\"open = false\" class=\"h-full flex items-center justify-end grow\" x-data=\"{ open: false }\">\n",
       "<!-- Hamburger Icon -->\n",
       "<button @click=\"open = !open\" class=\"lg:hidden h-full\">\n",
       "<svg class=\"w-6 h-6 text-stone-500\" fill=\"none\" height=\"14\" viewbox=\"-0.5 -0.5 14 14\" width=\"14\" xmlns=\"http://www.w3.org/2000/svg\"><g id=\"hamburger-menu-1--button-parallel-horizontal-lines-menu-navigation-three-hamburger\"><path d=\"M0.7688571428571428 1.5962142857142858h11.462285714285715\" id=\"Vector 185\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1\"></path><path d=\"M0.7688571428571428 6.239071428571429h11.462285714285715\" id=\"Vector 186\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1\"></path><path d=\"M0.7688571428571428 10.88192857142857h11.462285714285715\" id=\"Vector 187\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1\"></path></g></svg>\n",
       "</button>\n",
       "<!-- Mobile Menu -->\n",
       "<div @click=\"open = false\" class=\"fixed inset-0 z-50 bg-gray-600 bg-opacity-50 sm:hidden\" x-cloak=\"\" x-show=\"open\"></div>\n",
       "<div class=\"mobile-nav fixed inset-y-0 left-0 z-50 w-64 shadow-lg lg:hidden bg-stone-200 p-6\" x-cloak=\"\" x-show=\"open\">\n",
       "<a class=\"mb-3 block\" href=\"/subscribe\" title=\"Subscribe by Email\">\n",
       "<div class=\"flex items-center space-x-1.5 group-hover bg-[#FADD07] hover:bg-[#fbe439] py-2 px-4 rounded-xl\">\n",
       "<svg class=\"text-[#AA5F03]\" fill=\"none\" height=\"15\" viewbox=\"0 0 16 15\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M1.12369 11.6174C1.25877 12.7055 2.13777 13.565 3.22825 13.6791C4.7372 13.8367 6.30109 14.0033 7.90371 14.0033C9.50633 14.0033 11.0702 13.8367 12.5791 13.6791C13.6696 13.565 14.5486 12.7055 14.6837 11.6174C14.845 10.3183 15.0037 8.97489 15.0037 7.59973C15.0037 6.22456 14.845 4.88111 14.6837 3.58205C14.5486 2.49399 13.6696 1.63445 12.5791 1.52045C11.0702 1.36272 9.50633 1.19617 7.90371 1.19617C6.30109 1.19617 4.73719 1.36272 3.22825 1.52045C2.13777 1.63445 1.25877 2.49399 1.12368 3.58205C0.962399 4.88111 0.803711 6.22456 0.803711 7.59973C0.803711 8.97489 0.962399 10.3183 1.12369 11.6174Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M1.15527 3.2879L6.49688 7.49958C7.32189 8.15007 8.48531 8.15007 9.31032 7.49958L14.6519 3.2879\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "</svg>\n",
       "<span class=\"text-[#AA5F03]\">Subscribe by Email</span>\n",
       "</div>\n",
       "</a>\n",
       "<div>\n",
       "<a class=\"primary-nav-link !px-0.6\" href=\"/users/sign_in\" title=\"Log in\">\n",
       "<span class=\"link-text\">Log in</span>\n",
       "</a> </div>\n",
       "<span class=\"nav-slash md:mx-1 h-full bg-gradient-to-b from-[#CFCBC9] to-transparent w-[1px]\"></span>\n",
       "<div>\n",
       "<a class=\"primary-nav-link !px-0.6\" href=\"/users/sign_up\" title=\"Sign up\">\n",
       "<span class=\"link-text\">Sign up</span>\n",
       "</a> </div>\n",
       "<a class=\"primary-nav-link !px-0.6\" href=\"https://updates.emergentmind.com/\" title=\"Updates\">\n",
       "<span class=\"link-text\">Updates</span>\n",
       "</a>\n",
       "</div>\n",
       "<!-- Desktop Menu -->\n",
       "<div class=\"h-full w-full hidden lg:flex items-center justify-end space-x-0.6\">\n",
       "<div class=\"h-full flex items-center space-x-2 whitespace-nowrap\">\n",
       "<div>\n",
       "<a class=\"primary-nav-link !px-0.6\" href=\"/users/sign_in\" title=\"Log in\">\n",
       "<span class=\"link-text\">Log in</span>\n",
       "</a> </div>\n",
       "<span class=\"nav-slash md:mx-1 h-full bg-gradient-to-b from-[#CFCBC9] to-transparent w-[1px]\"></span>\n",
       "<div>\n",
       "<a class=\"primary-nav-link !px-0.6\" href=\"/users/sign_up\" title=\"Sign up\">\n",
       "<span class=\"link-text\">Sign up</span>\n",
       "</a> </div>\n",
       "<span class=\"nav-slash md:mx-1 h-full bg-gradient-to-b from-[#CFCBC9] to-transparent w-[1px]\"></span>\n",
       "</div>\n",
       "<div class=\"flex items-center h-full space-x-3.1\">\n",
       "<div class=\"relative pl-2 group\" title=\"Updates\">\n",
       "<svg fill=\"none\" height=\"17\" viewbox=\"0 0 17 17\" width=\"17\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path class=\"group-hover:fill-[#BE8204]\" d=\"M7.96875 0.53125C7.96875 0.239062 8.20781 0 8.5 0C8.79219 0 9.03125 0.239062 9.03125 0.53125V1.08906C11.7174 1.35469 13.8125 3.61914 13.8125 6.375V7.34121C13.8125 8.79219 14.3902 10.1834 15.4162 11.2127L15.5092 11.3057C15.7848 11.5813 15.9408 11.9564 15.9408 12.3449C15.9408 13.1584 15.2834 13.8158 14.4699 13.8158H2.5334C1.71992 13.8125 1.0625 13.1551 1.0625 12.3416C1.0625 11.9531 1.21855 11.5779 1.49414 11.3023L1.58711 11.2094C2.60977 10.1834 3.1875 8.79219 3.1875 7.34121V6.375C3.1875 3.61914 5.28262 1.35469 7.96875 1.08906V0.53125ZM8.5 2.125C6.15254 2.125 4.25 4.02754 4.25 6.375V7.34121C4.25 9.07441 3.5627 10.7379 2.33418 11.9631L2.24453 12.0527C2.16816 12.1291 2.125 12.232 2.125 12.3416C2.125 12.5674 2.30762 12.75 2.5334 12.75H14.4666C14.6924 12.75 14.875 12.5674 14.875 12.3416C14.875 12.232 14.8318 12.1291 14.7555 12.0527L14.6625 11.9598C13.4373 10.7346 12.7467 9.07109 12.7467 7.33789V6.375C12.7467 4.02754 10.8441 2.125 8.49668 2.125H8.5ZM7.49727 15.2303C7.64336 15.642 8.03848 15.9375 8.5 15.9375C8.96152 15.9375 9.35664 15.642 9.50273 15.2303C9.59902 14.9547 9.90449 14.8086 10.1801 14.9049C10.4557 15.0012 10.6018 15.3066 10.5055 15.5822C10.2133 16.409 9.42637 17 8.5 17C7.57363 17 6.78672 16.409 6.49453 15.5822C6.39824 15.3066 6.54102 15.0012 6.81992 14.9049C7.09883 14.8086 7.40098 14.9514 7.49727 15.2303Z\" fill=\"hsl(60,6%,38%)\"></path>\n",
       "</svg>\n",
       "<div class=\"absolute top-[-4px] left-[10px]\">\n",
       "<div class=\"relative\" id=\"headway\"></div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"group h-full\">\n",
       "<a class=\"\" href=\"/subscribe\" title=\"Subscribe by Email\">\n",
       "<div class=\"flex items-center space-x-1.5 group-hover bg-[#FADD07] hover:bg-[#fbe439] pl-4 pr-4.1 h-full rounded-b-xl text-[15px]\">\n",
       "<svg class=\"text-[#AA5F03] -translate-y-0.1\" fill=\"none\" height=\"15\" viewbox=\"0 0 16 15\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M1.12369 11.6174C1.25877 12.7055 2.13777 13.565 3.22825 13.6791C4.7372 13.8367 6.30109 14.0033 7.90371 14.0033C9.50633 14.0033 11.0702 13.8367 12.5791 13.6791C13.6696 13.565 14.5486 12.7055 14.6837 11.6174C14.845 10.3183 15.0037 8.97489 15.0037 7.59973C15.0037 6.22456 14.845 4.88111 14.6837 3.58205C14.5486 2.49399 13.6696 1.63445 12.5791 1.52045C11.0702 1.36272 9.50633 1.19617 7.90371 1.19617C6.30109 1.19617 4.73719 1.36272 3.22825 1.52045C2.13777 1.63445 1.25877 2.49399 1.12368 3.58205C0.962399 4.88111 0.803711 6.22456 0.803711 7.59973C0.803711 8.97489 0.962399 10.3183 1.12369 11.6174Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M1.15527 3.2879L6.49688 7.49958C7.32189 8.15007 8.48531 8.15007 9.31032 7.49958L14.6519 3.2879\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "</svg>\n",
       "<span class=\"text-[#AA5F03] -translate-y-0.1\">Subscribe</span>\n",
       "</div>\n",
       "</a> </div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</nav>\n",
       "<!-- /end: Main Navigation -->\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"w-full\">\n",
       "<div @keypress.window=\"handleKeyPress($event)\" class=\"mx-auto pt-2.1 sm:pt-2 relative max-w-[800px] w-full\" x-data=\"paper({&quot;id&quot;:378838,&quot;arxiv_paper_id&quot;:&quot;2403.14562&quot;,&quot;title&quot;:&quot;The Era of Semantic Decoding&quot;,&quot;paper_url&quot;:&quot;https://www.emergentmind.com/papers/2403.14562&quot;,&quot;published_at&quot;:&quot;2024-03-21T17:06:17.000Z&quot;,&quot;published_at_short&quot;:&quot;Mar 21&quot;,&quot;published_at_long&quot;:&quot;Mar 21, 2024 at  5:06pm UTC&quot;,&quot;age_in_seconds&quot;:525776,&quot;categories&quot;:[6,2,20,25],&quot;score&quot;:0.2982633465560919,&quot;status&quot;:&quot;enriched&quot;,&quot;has_bookmarked&quot;:false,&quot;temperature&quot;:96,&quot;figures_count&quot;:2,&quot;twitter_likes_count&quot;:110,&quot;reddit_points_count&quot;:0,&quot;hacker_news_points_count&quot;:0,&quot;youtube_paper_mentions_count&quot;:0,&quot;github_repos_count&quot;:0,&quot;github_pages_count&quot;:0,&quot;github_stars_count&quot;:0,&quot;html_analysis&quot;:&quot;  \\u003cfigure class=\\&quot;py-4\\&quot;\\u003e\\n      \\u003cdiv class=\\&quot;flex flex-col justify-center\\&quot;\\u003e\\n          \\u003cimg class=\\&quot;max-h-[400px]\\&quot; loading=\\&quot;lazy\\&quot; src=\\&quot;https://cdn.filestackcontent.com/resize=w:800,fit:max/auto_image/compress/85hZ6veSqa9FcPMlLE6P\\&quot; /\\u003e\\n      \\u003c/div\\u003e\\n\\n    \\u003cfigcaption class=\\&quot;text-sm italic text-center text-stone-500 text-balance\\&quot;\\u003e\\n      Analogy between syntactic decoding and semantic decoding in AI and human collaboration.\\n    \\u003c/figcaption\\u003e\\n  \\u003c/figure\\u003e\\n\\n  \\u003ch3 class=\\&quot;!border-none\\&quot;\\u003eOverview\\u003c/h3\\u003e\\n  \\n\\u003cul class=\\&quot;\\&quot;\\u003e\\n    \\u003cli\\u003e\\n        \\u003cp\\u003eThe paper introduces semantic decoding in AI, emphasizing optimized collaboration between language models, humans, and tools beyond traditional syntactic approaches.\\u003c/p\\u003e\\n    \\u003c/li\\u003e\\n    \\u003cli\\u003e\\n        \\u003cp\\u003eSemantic tokens, or thoughts, represent coherent text units, marking a shift from syntactic tokens to a more meaningful information-processing paradigm.\\u003c/p\\u003e\\n    \\u003c/li\\u003e\\n    \\u003cli\\u003e\\n        \\u003cp\\u003eSemantic decoding involves viewing AI interactions as optimization processes in a semantic space, aimed at maximizing utility for specific tasks.\\u003c/p\\u003e\\n    \\u003c/li\\u003e\\n    \\u003cli\\u003e\\n        \\u003cp\\u003eFuture directions suggest expanding semantic decoding through prompt engineering, improving human-computer interaction, and developing infrastructure for complex algorithms.\\u003c/p\\u003e\\n    \\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\n\\n  \\u003ch3 class='paper-heading'\\u003eIntroduction to \\u003cspan class=\\&quot;border-b whitespace-nowrap\\&quot; x-tooltip.placement.bottom.raw=\\&quot;A process in AI where interactions between systems (like language models, humans, tools) are optimized to process and exchange meaningful units of information, or 'semantic tokens', rather than just words or syntax.\\&quot;\\u003eSemantic Decoding\\u003c/span\\u003e\\u003c/h3\\u003e\\n\\u003cp\\u003eRecent advancements underscore the power of orchestrating the collaboration between LLMs, human input, and various tools, thereby extending the capabilities of AI systems beyond their current limitations. This paper introduces the concept of semantic decoding, presenting an \\u003cspan class=\\&quot;border-b whitespace-nowrap\\&quot; x-tooltip.placement.bottom.raw=\\&quot;A structured approach in AI development aimed at enhancing performance or efficacy according to specific criteria or tasks.\\&quot;\\u003eoptimization framework\\u003c/span\\u003e in semantic space where semantic processors, including LLMs, humans, and other tools, dynamically exchange \\u003cspan class=\\&quot;border-b whitespace-nowrap\\&quot; x-tooltip.placement.bottom.raw=\\&quot;Units of information processed in semantic decoding, representing coherent, meaningful concepts or thoughts, as opposed to mere syntactic units like words.\\&quot;\\u003esemantic tokens\\u003c/span\\u003e (thoughts) to construct high-utility outputs. This approach contrasts with traditional syntactic decoding where the focus is on generating sequences of \\u003cspan class=\\&quot;border-b whitespace-nowrap\\&quot; x-tooltip.placement.bottom.raw=\\&quot;Basic computational units in traditional language processing, such as words or parts of words, focusing on grammatical or syntactical structure.\\&quot;\\u003esyntactic tokens\\u003c/span\\u003e (e.g., words or sub-word units).\\u003c/p\\u003e\\n\\u003ch3 class='paper-heading'\\u003eTransition From Syntactic to Semantic Tokens\\u003c/h3\\u003e\\n\\u003cp\\u003eSyntactic tokens serve as the foundational computational units in language processing systems. In contrast, semantic tokens, or thoughts, are defined as coherent units of text that convey meaningful information. The shift from syntactic to semantic tokens allows for conceptualizing not only LLMs but also humans and tools as semantic processors. These processors manipulate semantic tokens and engage in exchanges to collaboratively solve tasks.\\u003c/p\\u003e\\n\\u003ch3 class='paper-heading'\\u003eDecoding at the Semantic Level\\u003c/h3\\u003e\\n\\u003cp\\u003eSemantic decoding reinterprets the interactions between semantic processors as optimization procedures in the semantic space, aiming to maximize utility defined by a specific task. Unlike syntactic decoding, which is limited by the need to produce syntactically coherent sequences, semantic decoding offers flexibility in crafting and navigating through meaningful concepts. This framework suggests viewing semantic processors and their orchestrated interactions as pragmatic computations, optimizing utility through the dynamic exchange of semantic tokens. Moreover, the development of semantic decoding algorithms, defined as orchestrated interactions among semantic processors, exemplifies this optimization process.\\u003c/p\\u003e\\n\\u003ch3 class='paper-heading'\\u003eOptimization in Semantic Space\\u003c/h3\\u003e\\n\\u003cp\\u003eVarious strategies for optimizing in the semantic space include:\\u003c/p\\u003e\\n\\n\\u003cul\\u003e\\n\\u003cli\\u003e\\u003cp\\u003e\\u003cstrong\\u003e\\u003cspan class=\\&quot;border-b whitespace-nowrap\\&quot; x-tooltip.placement.bottom.raw=\\&quot;Predefined workflows or strategies like Chain-of-Thought (CoT) that guide the generation of semantic tokens towards achieving high-utility outputs.\\&quot;\\u003eHeuristic Decoding Patterns\\u003c/span\\u003e\\u003c/strong\\u003e: Predefined workflows such as Chain-of-Thought (CoT) that dictate the generation of semantic tokens.\\u003c/p\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003cp\\u003e\\u003cstrong\\u003e\\u003cspan class=\\&quot;border-b whitespace-nowrap\\&quot; x-tooltip.placement.bottom.raw=\\&quot;A method combining sampling techniques with value models to navigate and construct meaningful semantic tokens efficiently.\\&quot;\\u003eguided Search in Semantic Space\\u003c/span\\u003e\\u003c/strong\\u003e: Combining sampling with value models to guide the exploration and construction of semantic tokens towards high-utility outputs.\\u003c/p\\u003e\\u003c/li\\u003e\\n\\u003cli\\u003e\\u003cp\\u003e\\u003cstrong\\u003e\\u003cspan class=\\&quot;border-b whitespace-nowrap\\&quot; x-tooltip.placement.bottom.raw=\\&quot;The process of training AI systems or controllers to better orchestrate the exchange of semantic tokens, enhancing collaboration among semantic processors.\\&quot;\\u003eLearning to Optimize\\u003c/span\\u003e\\u003c/strong\\u003e: Embracing optimization by training semantic processors to collaborate effectively or by training controllers to orchestrate the exchange of semantic tokens optimally.\\u003c/p\\u003e\\u003c/li\\u003e\\n\\u003c/ul\\u003e\\n\\u003ch3 class='paper-heading'\\u003eFuture Directions in Semantic Decoding\\u003c/h3\\u003e\\n\\u003cp\\u003eThe paper outlines numerous opportunities for further development within the semantic decoding framework. These include exploring \\u003cspan class=\\&quot;border-b whitespace-nowrap\\&quot; x-tooltip.placement.bottom.raw=\\&quot;The technique of designing prompts or inputs for AI systems in a way that steers the AI’s response towards desired outputs or behaviors.\\&quot;\\u003eprompt engineering\\u003c/span\\u003e, generating synthetic data flows, enhancing human-computer interaction, designing general AI assistants, developing evaluation and diagnostic methods, improving interpretability and control, exploring new semantic spaces, considering multimodal semantic tokens, and developing infrastructure to support complex semantic decoding algorithms.\\u003c/p\\u003e\\n\\u003ch3 class='paper-heading'\\u003eConclusion\\u003c/h3\\u003e\\n\\u003cp\\u003eSemantic decoding represents a paradigm shift in approaching AI system design and optimization, emphasizing semantic over syntactic processing. By harnessing the collective capabilities of semantic processors, including LLMs, tools, and the human mind, semantic decoding algorithms can navigate the richly structured semantic space to find meaningful and high-utility solutions. This perspective fosters innovation in AI development, opening up new avenues for research and application built upon the dynamic and pragmatic computation within the semantic space.\\u003c/p\\u003e\\n&quot;})\" x-init=\"trackPaperView();\">\n",
       "<div class=\"flex flex-col relative\">\n",
       "<!-- begin: Sidebar -->\n",
       "<div class=\"sidebar container px-2 sm:px-4 mx-auto -mb-4.5 relative sticky -top-[1px] z-30 border-none\" id=\"sidebar\">\n",
       "<div class=\"sidebar-background flex justify-center items-center xs:space-x-3 bg-stone-100/80 backdrop-blur-md border-b border-stone-200\">\n",
       "<div class=\"flex flex-row lg:flex-col space-x-7 relative z-20 pt-1 pb-1\">\n",
       "<!-- begin: Button -->\n",
       "<div class=\"flex items-center space-x-1\">\n",
       "<div class=\"\">\n",
       "<a @click.prevent=\"handleBookmarkClick(false)\" class=\"sidebar-button group\" href=\"/papers/2403.14562\" x-ref=\"bookmark_button\" x-tooltip=\"{\n",
       "            content: () =&gt; 'Or press m',\n",
       "            appendTo: document.querySelector('#sidebar')\n",
       "          }\">\n",
       "<svg class=\"fill-stone-600 group-hover:fill-active-link-color-darker select-none\" fill=\"none\" height=\"24\" viewbox=\"0 0 19 24\" width=\"19\" x-cloak=\"\" x-show=\"paper.has_bookmarked\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M1 3.00682V23.0588L9.355 17.2103L17.71 23.0588V3.00682C17.71 2.08395 16.9619 1.33582 16.039 1.33582H2.671C1.74814 1.33582 1 2.08395 1 3.00682Z\" stroke=\"hsl(33,6%,61%)\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path>\n",
       "</svg>\n",
       "<svg class=\"text-[hsl(33,6%,61%)] group-hover:text-active-link-color-darker select-none\" fill=\"none\" height=\"24\" viewbox=\"0 0 19 24\" width=\"19\" x-show=\"!paper.has_bookmarked\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M1 3.00682V23.0588L9.355 17.2103L17.71 23.0588V3.00682C17.71 2.08395 16.9619 1.33582 16.039 1.33582H2.671C1.74814 1.33582 1 2.08395 1 3.00682Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path>\n",
       "</svg>\n",
       "<span class=\"ml-1\">Bookmark</span>\n",
       "</a> </div>\n",
       "<span class=\"text-[hsl(60,6%,38%)]\">·</span>\n",
       "<a @click=\"trackViewTrendingPapersClick()\" class=\"sidebar-button group\" href=\"https://www.emergentmind.com/\">\n",
       "<span class=\"\">Trending Papers</span>\n",
       "<svg class=\"text-[hsl(33,6%,61%)] group-hover:text-active-link-color-darker select-none\" fill=\"none\" height=\"20\" viewbox=\"0 0 19 20\" width=\"19\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M0.521484 10.042H17.5703\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path>\n",
       "<path d=\"M9.56738 19.0926C12.8421 16.369 14.8421 14.5319 17.1983 11.7651C17.6069 11.2856 17.8313 10.6763 17.8313 10.0463C17.8313 9.41634 17.6069 8.80698 17.1983 8.32751C14.8435 5.56073 12.8421 3.72363 9.56738 1\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\"></path>\n",
       "</svg>\n",
       "</a>\n",
       "</div>\n",
       "<!-- /end: Button -->\n",
       "</div>\n",
       "<!-- /end: Sidebar -->\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"pt-5 sm:pt-5 mb-4 container px-2 sm:px-4 mx-auto relative\">\n",
       "<!-- begin: Emergent Mind analysis -->\n",
       "<div class=\"flex space-x-0\">\n",
       "<div class=\"flex chat-bubble white-chat-bubble w-full\">\n",
       "<!-- begin: Avatar -->\n",
       "<div class=\"mr-2.5 -translate-y-1.1 hidden md:inline-block grow-0\">\n",
       "<svg fill=\"none\" height=\"32\" viewbox=\"0 0 32 32\" width=\"32\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<g clip-path=\"url(#clip0_3188_9)\">\n",
       "<path d=\"M0 0H32V32H0V0Z\" fill=\"#F5F5F4\"></path>\n",
       "<path d=\"M16.1328 11.4V8.59998\" stroke=\"hsl(60,6%,38%)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"></path>\n",
       "<path d=\"M16.1332 11.4C14.1882 11.4 12.1572 11.4 10.4312 11.7C9.96415 11.7849 9.53303 12.0072 9.19311 12.3386C8.85318 12.6699 8.61993 13.0953 8.52323 13.56C8.28223 14.676 8.28223 15.596 8.28223 17.471C8.28223 19.346 8.28223 20.267 8.52323 21.383C8.72823 22.333 9.47523 23.075 10.4312 23.242C12.1572 23.544 14.1882 23.544 16.1332 23.544C18.0792 23.544 20.1102 23.544 21.8362 23.242C22.3032 23.1574 22.7343 22.9352 23.0742 22.604C23.4142 22.2728 23.6475 21.8477 23.7442 21.383C23.9842 20.267 23.9842 19.346 23.9842 17.471C23.9842 15.596 23.9842 14.676 23.7442 13.559C23.6473 13.0946 23.4139 12.6696 23.074 12.3386C22.7341 12.0076 22.3031 11.7856 21.8362 11.701C20.1102 11.399 18.0792 11.4 16.1332 11.4ZM16.1332 8.57003C16.4124 8.57612 16.69 8.5264 16.9497 8.42378C17.2094 8.32117 17.4459 8.16771 17.6455 7.97243C17.8451 7.77715 18.0037 7.54397 18.112 7.28658C18.2202 7.02919 18.276 6.75276 18.276 6.47353C18.276 6.19429 18.2202 5.91787 18.112 5.66047C18.0037 5.40308 17.8451 5.1699 17.6455 4.97462C17.4459 4.77934 17.2094 4.62589 16.9497 4.52327C16.69 4.42065 16.4124 4.37093 16.1332 4.37703C15.5771 4.37703 15.0437 4.59796 14.6504 4.99122C14.2572 5.38449 14.0362 5.91787 14.0362 6.47403C14.0362 7.03018 14.2572 7.56357 14.6504 7.95683C15.0437 8.35009 15.5771 8.57103 16.1332 8.57103V8.57003Z\" stroke=\"hsl(60,6%,38%)\" stroke-width=\"1.6\"></path>\n",
       "<path d=\"M13.305 15.8V14.957M18.962 15.8V14.957M13.106 19.357L13.288 19.548C13.579 19.853 13.982 20.025 14.404 20.025H17.864C18.284 20.025 18.687 19.853 18.978 19.548L19.161 19.358\" stroke=\"hsl(60,6%,38%)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.6\"></path>\n",
       "</g>\n",
       "<defs>\n",
       "<clippath id=\"clip0_3188_9\">\n",
       "<rect fill=\"white\" height=\"32\" rx=\"5\" width=\"32\"></rect>\n",
       "</clippath>\n",
       "</defs>\n",
       "</svg>\n",
       "</div>\n",
       "<!-- /end: Avatar -->\n",
       "<!-- begin: Username and content -->\n",
       "<div class=\"\">\n",
       "<div class=\"section-title\">\n",
       "      Emergent Mind\n",
       "    </div>\n",
       "<div class=\"mt-1.5 sm:mt-4 font-sitka\">\n",
       "<a class=\"break-smart\" href=\"https://arxiv.org/abs/2403.14562\" rel=\"nofollow\">\n",
       "<h1 class=\"text-[16px] md:text-[19px] leading-[1.4] md:leading-[1.3] text-[hsl(245,20%,50%)] no-underline font-sitka font-semibold inline\">\n",
       "          The Era of Semantic Decoding\n",
       "        </h1>\n",
       "<svg class=\"inline mx-0.5 -translate-y-1 w-2.6 text-[#686490]\" fill=\"none\" viewbox=\"0 0 523 523\"><path d=\"m87.223.199 412.244 23.334 23.334 412.244-87.681 7.071-9.193-200.111c-1.414-32.527-1.414-63.64 4.95-94.046l-374.06 374.06L.25 466.182l374.06-374.06c-34.649 7.779-50.912 7.072-94.046 4.95L80.153 87.88 87.222.2Z\" fill=\"currentColor\"></path></svg>\n",
       "</a>\n",
       "<span class=\"text-[#5B5852] text-[13px] leading-5 font-sitka\">(2403.14562)</span>\n",
       "<div class=\"text-[#5B5852] text-[14px] md:text-[16px] font-sitka mt-2 leading-[1.4]\">\n",
       "        Published Mar 21, 2024\n",
       "            in\n",
       "            <span class=\"\" x-tooltip.raw=\"Computation and Language\">cs.CL</span>\n",
       "<span class=\"-ml-[3px]\">,</span>\n",
       "<span class=\"\" x-tooltip.raw=\"Artificial Intelligence\">cs.AI</span>\n",
       "<span class=\"-ml-[3px]\">,</span>\n",
       "<span class=\"\" x-tooltip.raw=\"Human-Computer Interaction\">cs.HC</span>\n",
       "<span class=\"-ml-[3px]\">,</span>\n",
       "<span class=\"\" x-tooltip.raw=\"Multiagent Systems\">cs.MA</span>\n",
       "                and\n",
       "\n",
       "      </div>\n",
       "</div>\n",
       "<div class=\"mt-5 font-sitka\">\n",
       "<div class=\"rich-text font-sitka\">\n",
       "<div class=\"bg-stone-50/80 rounded px-4 md:px-6 py-4 md:-ml-6 md:-mr-1.5\">\n",
       "<h3 class=\"!my-0 !pb-3\">Abstract</h3>\n",
       "<div class=\"\">\n",
       "            Recent work demonstrated great promise in the idea of orchestrating collaborations between LLMs, human input, and various tools to address the inherent limitations of LLMs. We propose a novel perspective called semantic decoding, which frames these collaborative processes as optimization procedures in semantic space. Specifically, we conceptualize LLMs as semantic processors that manipulate meaningful pieces of information that we call semantic tokens (known thoughts). LLMs are among a large pool of other semantic processors, including humans and tools, such as search engines or code executors. Collectively, semantic processors engage in dynamic exchanges of semantic tokens to progressively construct high-utility outputs. We refer to these orchestrated interactions among semantic processors, optimizing and searching in semantic space, as semantic decoding algorithms. This concept draws a direct parallel to the well-studied problem of syntactic decoding, which involves crafting algorithms to best exploit auto-regressive language models for extracting high-utility sequences of syntactic tokens. By focusing on the semantic level and disregarding syntactic details, we gain a fresh perspective on the engineering of AI systems, enabling us to imagine systems with much greater complexity and capabilities. In this position paper, we formalize the transition from syntactic to semantic tokens as well as the analogy between syntactic and semantic decoding. Subsequently, we explore the possibilities of optimizing within the space of semantic tokens via semantic decoding algorithms. We conclude with a list of research opportunities and questions arising from this fresh perspective. The semantic decoding perspective offers a powerful abstraction for search and optimization directly in the space of meaningful concepts, with semantic tokens as the fundamental units of a new type of computation.\n",
       "          </div>\n",
       "</div>\n",
       "<figure class=\"py-4\">\n",
       "<div class=\"flex flex-col justify-center\">\n",
       "<img class=\"max-h-[400px]\" loading=\"lazy\" src=\"https://cdn.filestackcontent.com/resize=w:800,fit:max/auto_image/compress/85hZ6veSqa9FcPMlLE6P\"/>\n",
       "</div>\n",
       "<figcaption class=\"text-sm italic text-center text-stone-500 text-balance\">\n",
       "      Analogy between syntactic decoding and semantic decoding in AI and human collaboration.\n",
       "    </figcaption>\n",
       "</figure>\n",
       "<h3 class=\"!border-none\">Overview</h3>\n",
       "<ul class=\"\">\n",
       "<li>\n",
       "<p>The paper introduces semantic decoding in AI, emphasizing optimized collaboration between language models, humans, and tools beyond traditional syntactic approaches.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p>Semantic tokens, or thoughts, represent coherent text units, marking a shift from syntactic tokens to a more meaningful information-processing paradigm.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p>Semantic decoding involves viewing AI interactions as optimization processes in a semantic space, aimed at maximizing utility for specific tasks.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p>Future directions suggest expanding semantic decoding through prompt engineering, improving human-computer interaction, and developing infrastructure for complex algorithms.</p>\n",
       "</li>\n",
       "</ul>\n",
       "<h3 class=\"paper-heading\">Introduction to <span class=\"border-b whitespace-nowrap\" x-tooltip.placement.bottom.raw=\"A process in AI where interactions between systems (like language models, humans, tools) are optimized to process and exchange meaningful units of information, or 'semantic tokens', rather than just words or syntax.\">Semantic Decoding</span></h3>\n",
       "<p>Recent advancements underscore the power of orchestrating the collaboration between LLMs, human input, and various tools, thereby extending the capabilities of AI systems beyond their current limitations. This paper introduces the concept of semantic decoding, presenting an <span class=\"border-b whitespace-nowrap\" x-tooltip.placement.bottom.raw=\"A structured approach in AI development aimed at enhancing performance or efficacy according to specific criteria or tasks.\">optimization framework</span> in semantic space where semantic processors, including LLMs, humans, and other tools, dynamically exchange <span class=\"border-b whitespace-nowrap\" x-tooltip.placement.bottom.raw=\"Units of information processed in semantic decoding, representing coherent, meaningful concepts or thoughts, as opposed to mere syntactic units like words.\">semantic tokens</span> (thoughts) to construct high-utility outputs. This approach contrasts with traditional syntactic decoding where the focus is on generating sequences of <span class=\"border-b whitespace-nowrap\" x-tooltip.placement.bottom.raw=\"Basic computational units in traditional language processing, such as words or parts of words, focusing on grammatical or syntactical structure.\">syntactic tokens</span> (e.g., words or sub-word units).</p>\n",
       "<h3 class=\"paper-heading\">Transition From Syntactic to Semantic Tokens</h3>\n",
       "<p>Syntactic tokens serve as the foundational computational units in language processing systems. In contrast, semantic tokens, or thoughts, are defined as coherent units of text that convey meaningful information. The shift from syntactic to semantic tokens allows for conceptualizing not only LLMs but also humans and tools as semantic processors. These processors manipulate semantic tokens and engage in exchanges to collaboratively solve tasks.</p>\n",
       "<h3 class=\"paper-heading\">Decoding at the Semantic Level</h3>\n",
       "<p>Semantic decoding reinterprets the interactions between semantic processors as optimization procedures in the semantic space, aiming to maximize utility defined by a specific task. Unlike syntactic decoding, which is limited by the need to produce syntactically coherent sequences, semantic decoding offers flexibility in crafting and navigating through meaningful concepts. This framework suggests viewing semantic processors and their orchestrated interactions as pragmatic computations, optimizing utility through the dynamic exchange of semantic tokens. Moreover, the development of semantic decoding algorithms, defined as orchestrated interactions among semantic processors, exemplifies this optimization process.</p>\n",
       "<h3 class=\"paper-heading\">Optimization in Semantic Space</h3>\n",
       "<p>Various strategies for optimizing in the semantic space include:</p>\n",
       "<ul>\n",
       "<li><p><strong><span class=\"border-b whitespace-nowrap\" x-tooltip.placement.bottom.raw=\"Predefined workflows or strategies like Chain-of-Thought (CoT) that guide the generation of semantic tokens towards achieving high-utility outputs.\">Heuristic Decoding Patterns</span></strong>: Predefined workflows such as Chain-of-Thought (CoT) that dictate the generation of semantic tokens.</p></li>\n",
       "<li><p><strong><span class=\"border-b whitespace-nowrap\" x-tooltip.placement.bottom.raw=\"A method combining sampling techniques with value models to navigate and construct meaningful semantic tokens efficiently.\">guided Search in Semantic Space</span></strong>: Combining sampling with value models to guide the exploration and construction of semantic tokens towards high-utility outputs.</p></li>\n",
       "<li><p><strong><span class=\"border-b whitespace-nowrap\" x-tooltip.placement.bottom.raw=\"The process of training AI systems or controllers to better orchestrate the exchange of semantic tokens, enhancing collaboration among semantic processors.\">Learning to Optimize</span></strong>: Embracing optimization by training semantic processors to collaborate effectively or by training controllers to orchestrate the exchange of semantic tokens optimally.</p></li>\n",
       "</ul>\n",
       "<h3 class=\"paper-heading\">Future Directions in Semantic Decoding</h3>\n",
       "<p>The paper outlines numerous opportunities for further development within the semantic decoding framework. These include exploring <span class=\"border-b whitespace-nowrap\" x-tooltip.placement.bottom.raw=\"The technique of designing prompts or inputs for AI systems in a way that steers the AI’s response towards desired outputs or behaviors.\">prompt engineering</span>, generating synthetic data flows, enhancing human-computer interaction, designing general AI assistants, developing evaluation and diagnostic methods, improving interpretability and control, exploring new semantic spaces, considering multimodal semantic tokens, and developing infrastructure to support complex semantic decoding algorithms.</p>\n",
       "<h3 class=\"paper-heading\">Conclusion</h3>\n",
       "<p>Semantic decoding represents a paradigm shift in approaching AI system design and optimization, emphasizing semantic over syntactic processing. By harnessing the collective capabilities of semantic processors, including LLMs, tools, and the human mind, semantic decoding algorithms can navigate the richly structured semantic space to find meaningful and high-utility solutions. This perspective fosters innovation in AI development, opening up new avenues for research and application built upon the dynamic and pragmatic computation within the semantic space.</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<!-- /end: Username and content -->\n",
       "</div>\n",
       "<div class=\"hidden lg:block w-0\">\n",
       "<div class=\"flex relative\">\n",
       "<div class=\"flex flex-col items-center justify-center space-y-2.6 translate-x-3 ml-1.1 mt-3\">\n",
       "<!-- X/Twitter -->\n",
       "<a :href=\"`/papers/${paper.arxiv_paper_id}#x`\" class=\"flex flex-col space-y-1 items-center justify-center group\" x-cloak=\"\" x-show=\"paper.twitter_likes_count &gt; 0\" x-tooltip=\"{\n",
       "        content: () =&gt; $refs.twitter_template.innerHTML,\n",
       "        allowHTML: true,\n",
       "        appendTo: $root\n",
       "      }\">\n",
       "<svg class=\"social-icon-metric unsortable-social-media-icon\" fill=\"none\" height=\"20\" viewbox=\"0 0 20 20\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M3.33301 3.33331L13.1105 16.6666H16.6663L6.88884 3.33331H3.33301Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M3.33301 16.6666L8.97301 11.0266M11.023 8.97665L16.6663 3.33331\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "</svg>\n",
       "<div class=\"social-media-metric-vertical-text\" x-text=\"formatLargeNumber(paper.twitter_likes_count)\"></div>\n",
       "</a>\n",
       "<!-- Reddit -->\n",
       "<a :href=\"`/papers/${paper.arxiv_paper_id}#reddit`\" class=\"flex flex-col space-y-1 items-center justify-center group\" x-cloak=\"\" x-show=\"paper.reddit_points_count &gt; 0\" x-tooltip=\"{\n",
       "        content: () =&gt; $refs.reddit_template.innerHTML,\n",
       "        allowHTML: true,\n",
       "        appendTo: $root\n",
       "      }\">\n",
       "<svg class=\"social-icon-metric unsortable-social-media-icon\" fill=\"none\" height=\"23\" viewbox=\"0 0 23 23\" width=\"23\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M11.5007 7.66669C14.0383 7.66669 16.3192 8.45827 17.8975 9.71752C18.4375 9.52825 19.0273 9.53847 19.5604 9.74632C20.0935 9.95418 20.5346 10.3459 20.8039 10.8508C21.0732 11.3556 21.153 11.9401 21.0287 12.4986C20.9045 13.0572 20.5845 13.5528 20.1266 13.8959C20.1266 17.3363 16.2645 20.125 11.5016 20.125C6.82973 20.125 3.02515 17.4417 2.87661 14.0933L1.91828 13.8959C1.46037 13.5528 1.14036 13.0572 1.01614 12.4986C0.891913 11.9401 0.97167 11.3556 1.24099 10.8508C1.5103 10.3459 1.95139 9.95418 2.48446 9.74632C3.01754 9.53847 3.6074 9.52825 4.14736 9.71752C5.72478 8.45923 8.00561 7.66669 10.5433 7.66669H11.5007Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M11.5 7.66667L12.4583 2.875L18.2083 3.83333\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M17.25 3.83333C17.25 4.0875 17.351 4.33125 17.5307 4.51098C17.7104 4.6907 17.9542 4.79167 18.2083 4.79167C18.4625 4.79167 18.7063 4.6907 18.886 4.51098C19.0657 4.33125 19.1667 4.0875 19.1667 3.83333C19.1667 3.57917 19.0657 3.33541 18.886 3.15569C18.7063 2.97597 18.4625 2.875 18.2083 2.875C17.9542 2.875 17.7104 2.97597 17.5307 3.15569C17.351 3.33541 17.25 3.57917 17.25 3.83333Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M8.62565 12.9375C8.89029 12.9375 9.10482 12.723 9.10482 12.4584C9.10482 12.1937 8.89029 11.9792 8.62565 11.9792C8.36101 11.9792 8.14648 12.1937 8.14648 12.4584C8.14648 12.723 8.36101 12.9375 8.62565 12.9375Z\" fill=\"#8F8F80\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M14.3757 12.9375C14.6403 12.9375 14.8548 12.723 14.8548 12.4584C14.8548 12.1937 14.6403 11.9792 14.3757 11.9792C14.111 11.9792 13.8965 12.1937 13.8965 12.4584C13.8965 12.723 14.111 12.9375 14.3757 12.9375Z\" fill=\"#8F8F80\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M9.58398 16.2917C10.2232 16.6108 10.8614 16.7709 11.5007 16.7709C12.1399 16.7709 12.7781 16.6108 13.4173 16.2917\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "</svg>\n",
       "<div class=\"social-media-metric-vertical-text\" x-text=\"formatLargeNumber(paper.reddit_points_count)\"></div>\n",
       "</a>\n",
       "<!-- HackerNews -->\n",
       "<a :href=\"`/papers/${paper.arxiv_paper_id}#hackernews`\" class=\"flex flex-col space-y-1 items-center justify-center group\" x-cloak=\"\" x-show=\"paper.hacker_news_points_count &gt; 0\" x-tooltip=\"{\n",
       "        content: () =&gt; $refs.hackernews_template.innerHTML,\n",
       "        allowHTML: true,\n",
       "        appendTo: $root\n",
       "      }\">\n",
       "<svg class=\"social-icon-metric translate-y-[1px] unsortable-social-media-icon\" fill=\"none\" height=\"23\" viewbox=\"0 0 23 23\" width=\"23\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M3.83398 5.75004C3.83398 5.24171 4.03592 4.7542 4.39536 4.39475C4.75481 4.03531 5.24232 3.83337 5.75065 3.83337L17.2507 3.83337C17.759 3.83337 18.2465 4.03531 18.6059 4.39475C18.9654 4.7542 19.1673 5.24171 19.1673 5.75004V17.25C19.1673 17.7584 18.9654 18.2459 18.6059 18.6053C18.2465 18.9648 17.759 19.1667 17.2507 19.1667H5.75065C5.24232 19.1667 4.75481 18.9648 4.39536 18.6053C4.03592 18.2459 3.83398 17.7584 3.83398 17.25L3.83398 5.75004Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M7.66602 6.70831L11.4993 12.4583L15.3327 6.70831\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M11.5 16.2916V12.4583\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "</svg>\n",
       "<div class=\"social-media-metric-vertical-text\" x-text=\"formatLargeNumber(paper.hacker_news_points_count)\"></div>\n",
       "</a>\n",
       "<!-- YouTube -->\n",
       "<a :href=\"`/papers/${paper.arxiv_paper_id}#youtube`\" class=\"flex flex-col space-y-1 items-center justify-center group\" x-cloak=\"\" x-show=\"paper.youtube_paper_mentions_count &gt; 0\" x-tooltip=\"{\n",
       "        content: () =&gt; $refs.youtube_template.innerHTML,\n",
       "        allowHTML: true,\n",
       "        appendTo: $root\n",
       "      }\">\n",
       "<svg class=\"social-icon-metric translate-y-0.1 unsortable-social-media-icon\" fill=\"none\" height=\"23\" viewbox=\"0 0 24 23\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M1.99707 7.66671C1.99707 6.65004 2.41777 5.67502 3.16661 4.95613C3.91545 4.23724 4.9311 3.83337 5.99013 3.83337H17.9693C19.0283 3.83337 20.044 4.23724 20.7928 4.95613C21.5417 5.67502 21.9623 6.65004 21.9623 7.66671V15.3334C21.9623 16.35 21.5417 17.3251 20.7928 18.0439C20.044 18.7628 19.0283 19.1667 17.9693 19.1667H5.99013C4.9311 19.1667 3.91545 18.7628 3.16661 18.0439C2.41777 17.3251 1.99707 16.35 1.99707 15.3334V7.66671Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "<path d=\"M9.98242 8.625L14.9737 11.5L9.98242 14.375V8.625Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "</svg>\n",
       "<div class=\"social-media-metric-vertical-text\" x-text=\"formatLargeNumber(paper.youtube_paper_mentions_count)\"></div>\n",
       "</a>\n",
       "<!-- GitHub -->\n",
       "<a :href=\"`/papers/${paper.arxiv_paper_id}#github`\" class=\"flex flex-col space-y-1 items-center justify-center group\" x-cloak=\"\" x-show=\"paper.github_repos_count &gt; 0 || paper.github_pages_count &gt; 0\" x-tooltip=\"{\n",
       "        content: () =&gt; $refs.github_template.innerHTML,\n",
       "        allowHTML: true,\n",
       "        appendTo: $root\n",
       "      }\">\n",
       "<svg class=\"social-icon-metric translate-y-0 unsortable-social-media-icon\" fill=\"none\" height=\"22\" viewbox=\"0 0 22 22\" width=\"22\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M8.25 17.4167C4.30833 18.7 4.30833 15.125 2.75 14.6667M13.75 19.25V16.0417C13.75 15.125 13.8417 14.7583 13.2917 14.2083C15.8583 13.9333 18.3333 12.925 18.3333 8.70835C18.3322 7.6129 17.9048 6.56088 17.1417 5.77502C17.4996 4.82349 17.4666 3.76901 17.05 2.84168C17.05 2.84168 16.0417 2.56668 13.8417 4.03335C11.9783 3.54805 10.0217 3.54805 8.15833 4.03335C5.95833 2.56668 4.95 2.84168 4.95 2.84168C4.53336 3.76901 4.50041 4.82349 4.85833 5.77502C4.09517 6.56088 3.66778 7.6129 3.66667 8.70835C3.66667 12.925 6.14167 13.9333 8.70833 14.2083C8.15833 14.7583 8.15833 15.3083 8.25 16.0417V19.25\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.25\"></path>\n",
       "</svg>\n",
       "<div class=\"social-media-metric-vertical-text\" x-text=\"paper.github_repos_count &gt; 0 ? formatLargeNumber(paper.github_stars_count) : paper.github_pages_count\"></div>\n",
       "</a>\n",
       "</div>\n",
       "<template x-ref=\"twitter_template\">\n",
       "<div x-text=\"pluralize(paper.twitter_likes_count, 'like on X', 'likes on X')\"></div>\n",
       "</template>\n",
       "<template x-ref=\"hackernews_template\">\n",
       "<div x-text=\"pluralize(paper.hacker_news_points_count, 'upvote on HackerNews', 'upvotes on HackerNews')\"></div>\n",
       "</template>\n",
       "<template x-ref=\"reddit_template\">\n",
       "<div x-text=\"pluralize(paper.reddit_points_count, 'point on Reddit', 'points on Reddit')\"></div>\n",
       "</template>\n",
       "<template x-ref=\"youtube_template\">\n",
       "<div x-text=\"pluralize(paper.youtube_paper_mentions_count, 'video on YouTube', 'video on YouTube')\"></div>\n",
       "</template>\n",
       "<template x-ref=\"github_template\">\n",
       "<div x-show=\"paper.github_repos_count &gt; 0 &amp;&amp; paper.github_pages_count == 0\" x-text=\"pluralize(paper.github_stars_count, 'star on GitHub', 'stars on GitHub')\"></div>\n",
       "<div x-show=\"paper.github_repos_count == 0 &amp;&amp; paper.github_pages_count &gt; 0\" x-text=\"pluralize(paper.github_pages_count, 'GitHub page', 'GitHub page')\"></div>\n",
       "<div x-show=\"paper.github_repos_count &gt; 0 &amp;&amp; paper.github_pages_count &gt; 0\" x-text=\"`${pluralize(paper.github_stars_count, 'star', 'stars')} and ${pluralize(paper.github_pages_count, 'GitHub page', 'GitHub pages')}`\"></div>\n",
       "</template>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<!-- /end: Emergent Mind analysis -->\n",
       "<div class=\"mt-12 max-w-xl mx-auto\">\n",
       "<h2 class=\"text-2xl text-stone-700 font-semibold text-center text-balance\">Get summaries of trending AI papers delivered straight to your inbox</h2>\n",
       "<form accept-charset=\"UTF-8\" action=\"/subscribers\" class=\"mx-auto mt-6 flex space-x-1 items-center\" method=\"post\"><input autocomplete=\"off\" name=\"authenticity_token\" type=\"hidden\" value=\"SkrKKanmY2zUFW8790ntWORPezVCty4-df6BtrjTXofgsX5QEaQBuWQccYl9_GPxdrEmloBZMZgXSTND07NHGg\">\n",
       "<div class=\"flex flex-col sm:flex-row w-full space-y-2 sm:space-x-1 sm:space-y-0 justify-center items-center\">\n",
       "<div class=\"flex space-x-1\">\n",
       "<input class=\"w-[210px] sm:w-[260px] rounded-md border-0 p-2 text-gray-900 shadow-sm ring-1 ring-inset ring-gray-300 placeholder:text-gray-400 focus:ring-2 focus:ring-inset focus:ring-indigo-600\" data-1p-ignore=\"true\" id=\"subscriber_email\" name=\"subscriber[email]\" placeholder=\"Email address\" required=\"required\" type=\"text\"/>\n",
       "<select class=\"w-[130px] rounded-md border-0 py-1.5 pl-3 pr-10 text-gray-900 ring-1 ring-inset ring-gray-300 focus:ring-2 focus:ring-indigo-600 sm:text-sm sm:leading-6 h-full !py-2\" id=\"subscriber_frequency\" name=\"subscriber[frequency]\"><option selected=\"selected\" value=\"0\">Daily</option>\n",
       "<option value=\"1\">Weekly</option></select>\n",
       "<input autocomplete=\"off\" id=\"subscriber_source\" name=\"subscriber[source]\" type=\"hidden\" value=\"paper_page\"/>\n",
       "<div class=\"hidden\">\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_2\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"2\"/>\n",
       "<label for=\"subscriber_category_2\">Artificial Intelligence</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_6\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"6\"/>\n",
       "<label for=\"subscriber_category_6\">Computation and Language</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_8\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"8\"/>\n",
       "<label for=\"subscriber_category_8\">Computer Vision</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_9\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"9\"/>\n",
       "<label for=\"subscriber_category_9\">Computers and Society</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_11\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"11\"/>\n",
       "<label for=\"subscriber_category_11\">Distributed Computing</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_15\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"15\"/>\n",
       "<label for=\"subscriber_category_15\">Emerging Technologies</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_20\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"20\"/>\n",
       "<label for=\"subscriber_category_20\">Human-Computer Interaction</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_21\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"21\"/>\n",
       "<label for=\"subscriber_category_21\">Information Retrieval</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_23\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"23\"/>\n",
       "<label for=\"subscriber_category_23\">Machine Learning</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_25\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"25\"/>\n",
       "<label for=\"subscriber_category_25\">Multiagent Systems</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_26\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"26\"/>\n",
       "<label for=\"subscriber_category_26\">Multimedia</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_29\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"29\"/>\n",
       "<label for=\"subscriber_category_29\">Neural/Evolutionary Computing</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_35\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"35\"/>\n",
       "<label for=\"subscriber_category_35\">Robotics</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_37\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"37\"/>\n",
       "<label for=\"subscriber_category_37\">Sound</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_44\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"44\"/>\n",
       "<label for=\"subscriber_category_44\">Audio and Speech Processing</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_45\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"45\"/>\n",
       "<label for=\"subscriber_category_45\">Image and Video Processing</label>\n",
       "</div>\n",
       "<div>\n",
       "<input checked=\"checked\" class=\"form-checkbox\" id=\"subscriber_category_153\" name=\"subscriber[category_ids][]\" type=\"checkbox\" value=\"153\"/>\n",
       "<label for=\"subscriber_category_153\">Machine Learning</label>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div>\n",
       "<input class=\"bg-[#FADD07] hover:bg-[#fbe439] py-2 px-6 rounded-lg text-[#AA5F03] cursor-pointer\" data-disable-with=\"Subscribe\" name=\"commit\" type=\"submit\" value=\"Subscribe\"/>\n",
       "</div>\n",
       "</div>\n",
       "</input></form>\n",
       "<p class=\"text-center text-sm text-stone-600 mt-2 sm:mt-4\">Unsubscribe anytime.</p>\n",
       "</div>\n",
       "<!-- begin: Tweets -->\n",
       "<div class=\"pt-7.5\" id=\"x\">\n",
       "<div class=\"flex chat-bubble white-chat-bubble w-full\">\n",
       "<!-- begin: Avatar -->\n",
       "<div class=\"mr-2.5 -translate-y-1.1 hidden md:inline-block grow-0\">\n",
       "<svg class=\"w-[32px] h-[32px] rounded\" style=\"enable-background:new 0 0 24 24;\" version=\"1.1\" viewbox=\"0 0 24 24\" xml:space=\"preserve\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><g><polygon points=\"12.153992,10.729553 8.088684,5.041199 5.92041,5.041199 10.956299,12.087097 11.59021,12.97345    15.900635,19.009583 18.068909,19.009583 12.785217,11.615906  \"></polygon><path d=\"M21.15979,1H2.84021C1.823853,1,1,1.823853,1,2.84021v18.31958C1,22.176147,1.823853,23,2.84021,23h18.31958   C22.176147,23,23,22.176147,23,21.15979V2.84021C23,1.823853,22.176147,1,21.15979,1z M15.235352,20l-4.362549-6.213013   L5.411438,20H4l6.246887-7.104675L4,4h4.764648l4.130127,5.881958L18.06958,4h1.411377l-5.95697,6.775635L20,20H15.235352z\"></path></g></svg>\n",
       "</div>\n",
       "<!-- /end: Avatar -->\n",
       "<!-- begin: Username and content -->\n",
       "<div class=\"w-full\">\n",
       "<div class=\"section-title\">\n",
       "                X\n",
       "              </div>\n",
       "<div class=\"mt-1.5 sm:mt-4 rich-text font-sitka w-full\">\n",
       "<div class=\"flex flex-col space-y-4\">\n",
       "<div class=\"\">\n",
       "<blockquote class=\"twitter-tweet\">\n",
       "<a href=\"https://twitter.com/fly51fly/status/1771102244823531765\">https://twitter.com/fly51fly/status/1771102244823531765</a>\n",
       "</blockquote>\n",
       "</div>\n",
       "<div class=\"\">\n",
       "<blockquote class=\"twitter-tweet\">\n",
       "<a href=\"https://twitter.com/peyrardMax/status/1772214560742646132\">https://twitter.com/peyrardMax/status/1772214560742646132</a>\n",
       "</blockquote>\n",
       "</div>\n",
       "<div class=\"\">\n",
       "<blockquote class=\"twitter-tweet\">\n",
       "<a href=\"https://twitter.com/DarylC71/status/1771607003804139700\">https://twitter.com/DarylC71/status/1771607003804139700</a>\n",
       "</blockquote>\n",
       "</div>\n",
       "<div class=\"\">\n",
       "<blockquote class=\"twitter-tweet\">\n",
       "<a href=\"https://twitter.com/gm8xx8/status/1772362999900029420\">https://twitter.com/gm8xx8/status/1772362999900029420</a>\n",
       "</blockquote>\n",
       "</div>\n",
       "<div class=\"\">\n",
       "<blockquote class=\"twitter-tweet\">\n",
       "<a href=\"https://twitter.com/knishimae0531/status/1772462352975176089\">https://twitter.com/knishimae0531/status/1772462352975176089</a>\n",
       "</blockquote>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<!-- /end: Username and content -->\n",
       "</div>\n",
       "</div>\n",
       "<!-- /end: Tweets -->\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<footer class=\"text-center pt-4 sm:pt-8 pb-3 sm:pb-6 text-base\">\n",
       "<div class=\"flex items-center justify-center text-stone-600 font-verdana text-sm space-x-1 mb-4\">\n",
       "<a class=\"twitter-follow-button\" data-show-count=\"false\" href=\"https://twitter.com/EmergentMind\">Follow @EmergentMind</a>\n",
       "<div class=\"hidden sm:block\">for summaries of trending AI papers</div>\n",
       "</div>\n",
       "<ul class=\"text-gray-600 mb-4 sm:mb-3 flex flex-col sm:flex-row items-center justify-center\">\n",
       "<div>\n",
       "<a class=\"px-2 py-2.5 inline-block hover:text-active-link-color-darker transition duration-75 ease-out\" href=\"https://www.emergentmind.com/about\">About</a>\n",
       "<span class=\"text-section-line-gray\">|</span>\n",
       "<a class=\"px-2 py-2.5 inline-block hover:text-active-link-color-darker transition duration-75 ease-out\" href=\"https://www.emergentmind.com/hi\">Let's Chat</a>\n",
       "<span class=\"text-section-line-gray\">|</span>\n",
       "<a class=\"px-2 py-2.5 inline-block hover:text-active-link-color-darker transition duration-75 ease-out\" href=\"https://www.emergentmind.com/terms\">Terms</a>\n",
       "</div>\n",
       "<div>\n",
       "<span class=\"text-section-line-gray hidden sm:inline\">|</span>\n",
       "<a class=\"px-2 py-2.5 inline-block hover:text-active-link-color-darker transition duration-75 ease-out\" href=\"https://www.emergentmind.com/privacy\">Privacy</a>\n",
       "<span class=\"text-section-line-gray\">|</span>\n",
       "<a class=\"px-2 py-2.5 inline-block hover:text-active-link-color-darker transition duration-75 ease-out\" href=\"https://www.emergentmind.com/feeds/rss\">RSS</a>\n",
       "<span class=\"text-section-line-gray\">|</span>\n",
       "<a class=\"px-2 py-2.5 inline-block hover:text-active-link-color-darker transition duration-75 ease-out\" href=\"https://www.emergentmind.com/contact\">Contact</a>\n",
       "</div>\n",
       "</ul>\n",
       "</footer>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the URL into a BeautifulSoup object\n",
    "response = requests.get(args.url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Era of Semantic Decoding'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the title from soup\n",
    "\n",
    "\"\"\"\n",
    "<h1 class=\"text-[16px] md:text-[19px] leading-[1.4] md:leading-[1.3] text-[hsl(245,20%,50%)] no-underline font-sitka font-semibold inline\">\n",
    "          The Era of Semantic Decoding\n",
    "        </h1>\n",
    "\"\"\"\n",
    "\n",
    "title = soup.find(\"h1\").text.strip()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Arxiv ID\n",
    "# Iterate through spans until we regex match the arxiv ID structure\n",
    "\n",
    "\"\"\"\n",
    "<span class=\"text-[#5B5852] text-[13px] leading-5 font-sitka\">(2403.14562)</span>\n",
    "\"\"\"\n",
    "\n",
    "arxiv_id = None\n",
    "for span in soup.find_all(\"span\"):\n",
    "    match = re.match(r\"\\((\\d{4}\\.\\d{5})\\)\", span.text)\n",
    "    if match:\n",
    "        arxiv_id = match.group(1)\n",
    "        break\n",
    "    \n",
    "arxiv_id\n",
    "\n",
    "# We can also construct the URLs from the arxiv ID\n",
    "arxiv_url = f\"https://arxiv.org/abs/{arxiv_id}\"\n",
    "em_url = f\"https://www.emergentmind.com/papers/{arxiv_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-03-21'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the publication date\n",
    "\n",
    "\"\"\"\n",
    "<div class=\"text-[#5B5852] text-[14px] md:text-[16px] font-sitka mt-2 leading-[1.4]\">\n",
    "        Published Mar 21, 2024\n",
    "            in\n",
    "            <span class=\"\" x-tooltip.raw=\"Computation and Language\">cs.CL</span>\n",
    "                <span class=\"-ml-[3px]\">,</span>\n",
    "            <span class=\"\" x-tooltip.raw=\"Artificial Intelligence\">cs.AI</span>\n",
    "                <span class=\"-ml-[3px]\">,</span>\n",
    "            <span class=\"\" x-tooltip.raw=\"Human-Computer Interaction\">cs.HC</span>\n",
    "                <span class=\"-ml-[3px]\">,</span>\n",
    "            <span class=\"\" x-tooltip.raw=\"Multiagent Systems\">cs.MA</span>\n",
    "                and\n",
    "\n",
    "          by <a class=\"border-b border-gray-100 hover:text-stone-500\" href=\"https://www.emergentmind.com/search?q=Maxime+Peyrard\">Maxime Peyrard</a>, <a class=\"border-b border-gray-100 hover:text-stone-500\" href=\"https://www.emergentmind.com/search?q=Martin+Josifoski\">Martin Josifoski</a>, and <a class=\"border-b border-gray-100 hover:text-stone-500\" href=\"https://www.emergentmind.com/search?q=Robert+West\">Robert West</a>.\n",
    "      </div>\n",
    "\"\"\"\n",
    "\n",
    "# For the date, we can look for the text \"Published\" and extract the date\n",
    "date = None\n",
    "for div in soup.find_all(\"div\"):\n",
    "    if \"Published\" in div.text:\n",
    "        match = re.search(r\"Published (\\w+ \\d{1,2}, \\d{4})\", div.text)\n",
    "        if match:\n",
    "            date = match.group(1)\n",
    "        break\n",
    "    \n",
    "# This comes out like 'Mar 21, 2024', so we can parse it with datetime\n",
    "date = datetime.datetime.strptime(date, \"%b %d, %Y\").date()\n",
    "date = date.strftime(\"%Y-%m-%d\")\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recent work demonstrated great promise in the idea of orchestrating collaborations between LLMs, human input, and various tools to address the inherent limitations of LLMs. We propose a novel perspective called semantic decoding, which frames these collaborative processes as optimization procedures in semantic space. Specifically, we conceptualize LLMs as semantic processors that manipulate meaningful pieces of information that we call semantic tokens (known thoughts). LLMs are among a large pool of other semantic processors, including humans and tools, such as search engines or code executors. Collectively, semantic processors engage in dynamic exchanges of semantic tokens to progressively construct high-utility outputs. We refer to these orchestrated interactions among semantic processors, optimizing and searching in semantic space, as semantic decoding algorithms. This concept draws a direct parallel to the well-studied problem of syntactic decoding, which involves crafting algorithms to best exploit auto-regressive language models for extracting high-utility sequences of syntactic tokens. By focusing on the semantic level and disregarding syntactic details, we gain a fresh perspective on the engineering of AI systems, enabling us to imagine systems with much greater complexity and capabilities. In this position paper, we formalize the transition from syntactic to semantic tokens as well as the analogy between syntactic and semantic decoding. Subsequently, we explore the possibilities of optimizing within the space of semantic tokens via semantic decoding algorithms. We conclude with a list of research opportunities and questions arising from this fresh perspective. The semantic decoding perspective offers a powerful abstraction for search and optimization directly in the space of meaningful concepts, with semantic tokens as the fundamental units of a new type of computation.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the abstract, find the H3 tag with the text \"Abstract\"\n",
    "# The next sibling is the actual abstract\n",
    "\n",
    "abstract = None\n",
    "for h3 in soup.find_all(\"h3\"):\n",
    "    if h3.text.strip() == \"Abstract\":\n",
    "        abstract = h3.find_next_sibling(\"div\").text.strip()\n",
    "        break\n",
    "    \n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to dataframe\n",
    "new_row = pd.DataFrame(\n",
    "    {\n",
    "        \"arxiv_id\": [arxiv_id],\n",
    "        \"title\": [title],\n",
    "        \"publication_date\": [date],\n",
    "        \"abstract\": [abstract],\n",
    "        \"notes\": [args.notes],\n",
    "        \"arxiv_url\": [arxiv_url],\n",
    "        \"em_url\": [em_url],\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Save the dataframe\n",
    "df.to_excel(f\"{GOOGLE_DRIVE_PATH}/arxiv_papers.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
